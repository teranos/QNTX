# Session Handover: Shared Rust Crate & Inference Plugin

**Date**: 2026-01-08
**Branch**: `claude/plan-shared-rust-crate-T7RwQ`

---

## Summary

Created a shared `qntx` Rust crate and a new `qntx-inference` plugin for local embedding generation. All Rust projects now use a unified Cargo workspace.

---

## Changes Made

### 1. Cargo Workspace (`Cargo.toml` at root)

```toml
[workspace]
members = [
    "crates/qntx",
    "crates/qntx-inference",
    "qntx-python",
    "web/src-tauri",
]
exclude = [
    "ats/ax/fuzzy-ax",      # CGO library for Go
    "types/generated/rust", # Legacy, superseded by crates/qntx/src/types/
]
```

Shared dependencies defined in `[workspace.dependencies]` for consistency.

### 2. Shared Crate (`crates/qntx/`)

```
crates/qntx/
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ build.rs              # Proto compilation (feature-gated)
â””â”€â”€ src/
    â”œâ”€â”€ lib.rs
    â”œâ”€â”€ error.rs          # Common error types (thiserror)
    â”œâ”€â”€ tracing.rs        # Logging with segment prefixes (ê©œ, âœ¿, â€)
    â”œâ”€â”€ types/            # Generated from Go source
    â”‚   â”œâ”€â”€ mod.rs
    â”‚   â”œâ”€â”€ async.rs      # Job, JobStatus, Progress
    â”‚   â”œâ”€â”€ budget.rs
    â”‚   â”œâ”€â”€ schedule.rs
    â”‚   â”œâ”€â”€ server.rs
    â”‚   â”œâ”€â”€ sym.rs        # QNTX symbols
    â”‚   â””â”€â”€ types.rs
    â””â”€â”€ plugin/           # gRPC plugin infrastructure
        â”œâ”€â”€ mod.rs
        â”œâ”€â”€ server.rs     # PluginServer builder
        â””â”€â”€ shutdown.rs   # Graceful shutdown signal handling
```

**Features**:
- `types` (default) - Just the generated types
- `plugin` - Full gRPC plugin infrastructure (requires protoc)

### 3. Inference Plugin (`crates/qntx-inference/`)

```
crates/qntx-inference/
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ README.md             # Documentation on ONNX and usage
â””â”€â”€ src/
    â”œâ”€â”€ main.rs           # CLI entry point
    â”œâ”€â”€ lib.rs
    â”œâ”€â”€ engine.rs         # ONNX inference engine
    â””â”€â”€ service.rs        # gRPC DomainPluginService
```

**Dependencies**:
- `ort` (ONNX Runtime) v2.0.0-rc.9
- `tokenizers` v0.20 (HuggingFace)
- `qntx` with `plugin` feature

**Endpoints**:
- `POST /embed` - Generate embeddings
- `POST /v1/embeddings` - OpenAI-compatible
- `GET /health` - Health check

### 4. Migrated Existing Crates

**`qntx-python-plugin`**:
- Now depends on `qntx` crate
- Uses workspace dependencies
- Nix build updated to use workspace `Cargo.lock`

**`qntx-app` (Tauri)**:
- Now uses `qntx::types` instead of `qntx-types`
- Import changed: `use qntx::types::{sym, Job, JobStatus, ...}`

### 5. Type Generation

**Current flow** (transitional):
1. `typegen --lang rust` outputs to `types/generated/rust/`
2. `flake.nix` syncs `.rs` files to `crates/qntx/src/types/`
3. Excludes `lib.rs` and `mod.rs` (we have custom ones)
4. Fixes `server.rs` import (`crate::` â†’ `super::`)

**TODO**: Update typegen to output directly to `crates/qntx/src/types/`, then delete `types/generated/rust/`.

---

## Files Modified

| File | Change |
|------|--------|
| `Cargo.toml` | NEW - Workspace root |
| `Cargo.lock` | Updated for workspace |
| `crates/qntx/*` | NEW - Shared crate |
| `crates/qntx-inference/*` | NEW - Inference plugin |
| `qntx-python/Cargo.toml` | Uses workspace deps |
| `qntx-python/Cargo.lock` | DELETED - Uses workspace |
| `web/src-tauri/Cargo.toml` | Uses workspace deps |
| `web/src-tauri/src/main.rs` | Updated imports |
| `flake.nix` | Updated for workspace, added type sync |
| `docs/plans/phase-2-qntx-crate.md` | Phase 2 TODO list |

---

## Testing Needed

### Local (requires Nix)

```bash
# Build qntx crate (types only)
cargo build -p qntx

# Build qntx crate with plugin feature (requires protoc)
nix develop
cargo build -p qntx --features plugin

# Build inference plugin
cargo build -p qntx-inference

# Build python plugin
nix build .#qntx-python

# Run all workspace tests
cargo test --workspace
```

### CI Checks

- [ ] `cargo fmt --check --all` - Formatting
- [ ] `cargo clippy --workspace` - Lints
- [ ] Nix builds for qntx-python-plugin
- [ ] Tauri build (desktop)

### Manual Testing

- [ ] Start qntx-inference with a model, call `/embed`
- [ ] Verify qntx-app still works with new type imports
- [ ] Run `make types` and verify sync works

---

## Known Issues

1. **Proto compilation requires Nix** - `cargo build -p qntx --features plugin` needs `protoc`
2. **Legacy types directory** - `types/generated/rust/` still exists, excluded from workspace
3. **ONNX Runtime version** - Using `2.0.0-rc.9` (prerelease)

---

## UI Suggestions for Inference Plugin

### Settings Panel (â‰¡ am â†’ Plugins â†’ Inference)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Local Inference                              [ON/OFF]â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚ Model                                               â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ~/.qntx/models/minilm/model.onnx          [...] â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â”‚ Tokenizer                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ~/.qntx/models/minilm/tokenizer.json      [...] â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Advanced â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”‚
â”‚                                                     â”‚
â”‚ Max Sequence Length    [512        ]               â”‚
â”‚ Normalize Embeddings   [âœ“]                         â”‚
â”‚ Inference Threads      [0 (auto)   ]               â”‚
â”‚                                                     â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Status â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”‚
â”‚                                                     â”‚
â”‚ â— Model loaded (384 dimensions)                    â”‚
â”‚   all-MiniLM-L6-v2                                 â”‚
â”‚                                                     â”‚
â”‚ [Download Model...] [Test Embedding]               â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model Browser (future)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Available Models                           [Search] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚ â˜… Recommended                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ all-MiniLM-L6-v2                                â”‚ â”‚
â”‚ â”‚ 384 dims Â· 23MB Â· Fast                 [Install]â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ bge-small-en-v1.5                               â”‚ â”‚
â”‚ â”‚ 384 dims Â· 45MB Â· Retrieval-focused    [Install]â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â”‚ â—‹ Installed                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ âœ“ all-MiniLM-L6-v2              [Use] [Delete] â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Integration with â‹ˆ ax (semantic search)

```
â‹ˆ ax "people who worked at tech companies"
     â”œâ”€ ğŸ” Fuzzy: "tech companies" â†’ 3 matches
     â””â”€ ğŸ§  Semantic: embedding similarity â†’ 12 matches

Results (sorted by relevance):
  0.94  Alice (as software_engineer at Google)
  0.91  Bob (as product_manager at Meta)
  0.87  Charlie (as founder at TechStartup)
  ...
```

---

## Next Steps (Phase 2)

See `docs/plans/phase-2-qntx-crate.md`:

1. **Update typegen** to output directly to `crates/qntx/src/types/`
2. **Delete** `types/generated/rust/` directory
3. **Migrate qntx-python-plugin** to use `qntx::plugin::proto`
4. **Add integration** with ax for semantic search

---

## Commits in This Session

```
2b082c2 Add TODO for deleting legacy types/generated/rust directory
f5f8faa Exclude types/generated/rust from workspace
28d7639 Use workspace Cargo.lock for qntx-python Nix build
2af4a14 Fix Rust formatting and exclude fuzzy-ax from workspace
733766d Add documentation for qntx-inference plugin
38da168 Add qntx-inference plugin for local embedding generation
4e8c1f5 Add shared qntx Rust crate with workspace configuration
```
